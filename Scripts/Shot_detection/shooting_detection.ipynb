{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0156b772-4462-48f3-8f68-5f71acec6248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import xml.etree.ElementTree as ET\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dacf3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the versions\n",
    "# opencv_version = cv2.__version__\n",
    "# ultralytics_version = ultralytics.__version__\n",
    "# mediapipe_version = mp.__version__\n",
    "\n",
    "# # Write the versions to a requirements.txt file\n",
    "# with open('/content/drive/MyDrive/bollogy/requirements.txt', 'w') as f:\n",
    "#     f.write(f\"opencv-python=={opencv_version}\\n\")\n",
    "#     f.write(f\"ultralytics=={ultralytics_version}\\n\")\n",
    "#     f.write(f\"mediapipe=={mediapipe_version}\\n\")\n",
    "#     f.close()\n",
    "\n",
    "# print(\"requirements.txt file has been created with the following content:\")\n",
    "# print(f\"opencv-python=={opencv_version}\")\n",
    "# print(f\"ultralytics=={ultralytics_version}\")\n",
    "# print(f\"mediapipe=={mediapipe_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66106dbe-fffb-47e1-9ba6-c2f925e3ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 model\n",
    "model_path = 'yolov8n.pt'  # Using a pre-trained YOLOv8 model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=True, model_complexity=2, enable_segmentation=False, min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2b79e8e-6435-4038-8e6c-79342c5f8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save results\n",
    "bbox_output_dir = 'C:/Users/alimo/OneDrive/Documents/FRT/YOLO MediaPipe Pose Detection/YOLOv8-Mediapipe-Pose-Detection/Output/Detected_Bbox'\n",
    "Handsup_output_dir = 'C:/Users/alimo/OneDrive/Documents/FRT/YOLO MediaPipe Pose Detection/YOLOv8-Mediapipe-Pose-Detection/Output/Hands_Up'\n",
    "xml_dir = 'C:/Users/alimo/OneDrive/Documents/FRT/YOLO MediaPipe Pose Detection/YOLOv8-Mediapipe-Pose-Detection/Output/XML_Files'\n",
    "\n",
    "video_dir = 'C:/Users/alimo/OneDrive/Documents/FRT/YOLO MediaPipe Pose Detection/YOLOv8-Mediapipe-Pose-Detection/Videos_data'  # Update with video path\n",
    "\n",
    "os.makedirs(Handsup_output_dir, exist_ok=True)\n",
    "os.makedirs(xml_dir, exist_ok=True)\n",
    "os.makedirs(bbox_output_dir, exist_ok=True)\n",
    "\n",
    "# Confidence threshold\n",
    "confidence_threshold = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c8108a5-0fe8-4d2d-aca5-35cad3efae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose_landmarks(image):\n",
    "    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    if results.pose_landmarks:\n",
    "        keypoints = [landmark for landmark in results.pose_landmarks.landmark if landmark.visibility > confidence_threshold]\n",
    "        if len(keypoints) > len(results.pose_landmarks.landmark) / 2:\n",
    "            return results.pose_landmarks\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4cf6483-50e3-4424-b621-e9b3b6595d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_pose(landmarks):\n",
    "    if not landmarks:\n",
    "        return \"No pose detected\"\n",
    "\n",
    "    landmarks_list = [landmark for landmark in landmarks.landmark]\n",
    "\n",
    "    left_wrist = landmarks_list[mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
    "    right_wrist = landmarks_list[mp_pose.PoseLandmark.RIGHT_WRIST.value]\n",
    "    left_eye = landmarks_list[mp_pose.PoseLandmark.LEFT_EYE.value]\n",
    "    right_eye = landmarks_list[mp_pose.PoseLandmark.RIGHT_EYE.value]\n",
    "    nose = landmarks_list[mp_pose.PoseLandmark.NOSE.value]\n",
    "\n",
    "    # Check if either wrist is above the eyes or nose\n",
    "    if (left_wrist.y < left_eye.y or left_wrist.y < nose.y) and (right_wrist.y < right_eye.y or right_wrist.y < nose.y):\n",
    "        return \"Hands Up\"\n",
    "    else:\n",
    "        return \"Other Pose\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec3169a-2552-4cd4-951f-5f399cb25a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml_for_bounding_box(bounding_box, file_name, save_directory):\n",
    "    \"\"\"\n",
    "    Create an XML file for a given bounding box and file name, and save it to the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    bounding_box (tuple): A tuple containing (xmin, ymin, xmax, ymax).\n",
    "    file_name (str): The name of the file (without extension).\n",
    "    save_directory (str): The directory where the XML file will be saved.\n",
    "\n",
    "    Returns:\n",
    "    str: The name of the created XML file.\n",
    "    \"\"\"\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    # Define the root element\n",
    "    annotation = ET.Element('annotation')\n",
    "\n",
    "    # Define the folder element\n",
    "    folder = ET.SubElement(annotation, 'folder')\n",
    "    folder.text = 'images'\n",
    "\n",
    "    # Define the filename element\n",
    "    filename = ET.SubElement(annotation, 'filename')\n",
    "    filename.text = f\"{file_name}.jpg\"\n",
    "\n",
    "    # Define the path element\n",
    "    path = ET.SubElement(annotation, 'path')\n",
    "    path.text = os.path.join('Output\\XML_Files', f\"{file_name}.jpg\")\n",
    "\n",
    "    # Define the source element\n",
    "    source = ET.SubElement(annotation, 'source')\n",
    "    database = ET.SubElement(source, 'database')\n",
    "    database.text = 'Unknown'\n",
    "\n",
    "    # Define the size element\n",
    "    size = ET.SubElement(annotation, 'size')\n",
    "    width = ET.SubElement(size, 'width')\n",
    "    width.text = '1280'  # Placeholder value\n",
    "    height = ET.SubElement(size, 'height')\n",
    "    height.text = '720'  # Placeholder value\n",
    "    depth = ET.SubElement(size, 'depth')\n",
    "    depth.text = '3'  # Assuming RGB images\n",
    "\n",
    "    # Define the segmented element\n",
    "    segmented = ET.SubElement(annotation, 'segmented')\n",
    "    segmented.text = '0'\n",
    "\n",
    "    # Define the object element\n",
    "    obj = ET.SubElement(annotation, 'object')\n",
    "    name = ET.SubElement(obj, 'name')\n",
    "    name.text = 'shooting player'\n",
    "    pose = ET.SubElement(obj, 'pose')\n",
    "    pose.text = 'Unspecified'\n",
    "    truncated = ET.SubElement(obj, 'truncated')\n",
    "    truncated.text = '0'\n",
    "    difficult = ET.SubElement(obj, 'difficult')\n",
    "    difficult.text = '0'\n",
    "    bndbox = ET.SubElement(obj, 'bndbox')\n",
    "    xmin = ET.SubElement(bndbox, 'xmin')\n",
    "    xmin.text = str(int(bounding_box[0]))\n",
    "    ymin = ET.SubElement(bndbox, 'ymin')\n",
    "    ymin.text = str(int(bounding_box[1]))\n",
    "    xmax = ET.SubElement(bndbox, 'xmax')\n",
    "    xmax.text = str(int(bounding_box[2]))\n",
    "    ymax = ET.SubElement(bndbox, 'ymax')\n",
    "    ymax.text = str(int(bounding_box[3]))\n",
    "\n",
    "    # Convert the tree to a string and write it to a file\n",
    "    tree = ET.ElementTree(annotation)\n",
    "    xml_file_name = os.path.join(save_directory, f\"{file_name}.xml\")\n",
    "    tree.write(xml_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa9a3171-1ff6-4591-bbe5-f56aa032291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_person(model, frame):\n",
    "    results = model.predict(frame)\n",
    "    detected_persons = []\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy.cpu().numpy()\n",
    "        scores = result.boxes.conf.cpu().numpy()\n",
    "        class_ids = result.boxes.cls.cpu().numpy()\n",
    "\n",
    "        for box, score, class_id in zip(boxes, scores, class_ids):\n",
    "            if class_id == 0 and score > confidence_threshold:  # Class 0 is 'person' in COCO dataset\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                height = y2 - y1\n",
    "                width = x2 - x1\n",
    "                center_x = (x1 + x2) // 2\n",
    "                x1 = center_x - height // 2\n",
    "                x2 = center_x + height // 2\n",
    "                x1 = max(0, x1)\n",
    "                x2 = min(frame.shape[1], x2)\n",
    "                cropped_person = frame[y1:y2, x1:x2]\n",
    "                landmarks = get_pose_landmarks(cropped_person)\n",
    "                pose_label = classify_pose(landmarks)\n",
    "                if pose_label == \"Hands Up\":\n",
    "                    print('Hands UP')\n",
    "                    detected_persons.append((box, score, class_id, pose_label))\n",
    "    return detected_persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a4218d7-1adb-492f-9000-8e4ba7f8e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_name(length=8):\n",
    "    \"\"\"Generate a random string of letters and digits.\"\"\"\n",
    "    chars = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(chars) for _ in range(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3eb9cf1-84f9-48ac-99fd-57863e8be449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 chair, 178.8ms\n",
      "Speed: 3.0ms preprocess, 178.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 134.8ms\n",
      "Speed: 4.0ms preprocess, 134.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 156.9ms\n",
      "Speed: 2.0ms preprocess, 156.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "3\n",
      "\n",
      "0: 384x640 2 persons, 182.1ms\n",
      "Speed: 2.0ms preprocess, 182.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "4\n",
      "\n",
      "0: 384x640 2 persons, 158.7ms\n",
      "Speed: 2.0ms preprocess, 158.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "5\n",
      "\n",
      "0: 384x640 2 persons, 176.9ms\n",
      "Speed: 3.0ms preprocess, 176.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "6\n",
      "\n",
      "0: 384x640 2 persons, 145.8ms\n",
      "Speed: 2.0ms preprocess, 145.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "7\n",
      "\n",
      "0: 384x640 2 persons, 159.5ms\n",
      "Speed: 1.9ms preprocess, 159.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "8\n",
      "\n",
      "0: 384x640 2 persons, 146.8ms\n",
      "Speed: 0.9ms preprocess, 146.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "9\n",
      "\n",
      "0: 384x640 2 persons, 150.0ms\n",
      "Speed: 1.0ms preprocess, 150.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "10\n",
      "\n",
      "0: 384x640 2 persons, 140.6ms\n",
      "Speed: 2.0ms preprocess, 140.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "11\n",
      "\n",
      "0: 384x640 2 persons, 137.4ms\n",
      "Speed: 2.0ms preprocess, 137.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "12\n",
      "\n",
      "0: 384x640 2 persons, 150.3ms\n",
      "Speed: 3.1ms preprocess, 150.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "13\n",
      "\n",
      "0: 384x640 2 persons, 147.0ms\n",
      "Speed: 2.0ms preprocess, 147.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "14\n",
      "\n",
      "0: 384x640 2 persons, 150.3ms\n",
      "Speed: 1.9ms preprocess, 150.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "15\n",
      "\n",
      "0: 384x640 2 persons, 146.1ms\n",
      "Speed: 2.0ms preprocess, 146.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "16\n",
      "\n",
      "0: 384x640 2 persons, 160.0ms\n",
      "Speed: 1.9ms preprocess, 160.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "17\n",
      "\n",
      "0: 384x640 2 persons, 165.8ms\n",
      "Speed: 1.0ms preprocess, 165.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "18\n",
      "\n",
      "0: 384x640 2 persons, 145.8ms\n",
      "Speed: 2.0ms preprocess, 145.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "19\n",
      "\n",
      "0: 384x640 2 persons, 148.9ms\n",
      "Speed: 2.0ms preprocess, 148.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "20\n",
      "\n",
      "0: 384x640 2 persons, 148.8ms\n",
      "Speed: 2.0ms preprocess, 148.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "21\n",
      "\n",
      "0: 384x640 2 persons, 161.6ms\n",
      "Speed: 1.0ms preprocess, 161.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "22\n",
      "\n",
      "0: 384x640 4 persons, 1 traffic light, 139.2ms\n",
      "Speed: 2.1ms preprocess, 139.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "23\n",
      "\n",
      "0: 384x640 3 persons, 146.0ms\n",
      "Speed: 2.0ms preprocess, 146.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "24\n",
      "\n",
      "0: 384x640 3 persons, 149.6ms\n",
      "Speed: 1.0ms preprocess, 149.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25\n",
      "\n",
      "0: 384x640 3 persons, 134.2ms\n",
      "Speed: 2.0ms preprocess, 134.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "26\n",
      "\n",
      "0: 384x640 3 persons, 133.2ms\n",
      "Speed: 1.9ms preprocess, 133.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "27\n",
      "\n",
      "0: 384x640 3 persons, 138.3ms\n",
      "Speed: 2.0ms preprocess, 138.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "28\n",
      "\n",
      "0: 384x640 3 persons, 138.2ms\n",
      "Speed: 2.0ms preprocess, 138.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "29\n",
      "\n",
      "0: 384x640 3 persons, 134.6ms\n",
      "Speed: 2.1ms preprocess, 134.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "30\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 146.6ms\n",
      "Speed: 2.0ms preprocess, 146.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "31\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 134.3ms\n",
      "Speed: 1.9ms preprocess, 134.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "32\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 146.1ms\n",
      "Speed: 2.0ms preprocess, 146.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "33\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 165.3ms\n",
      "Speed: 2.2ms preprocess, 165.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "34\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 148.1ms\n",
      "Speed: 2.1ms preprocess, 148.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "35\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 152.9ms\n",
      "Speed: 2.0ms preprocess, 152.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "36\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 159.8ms\n",
      "Speed: 2.0ms preprocess, 159.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "37\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 138.5ms\n",
      "Speed: 1.0ms preprocess, 138.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "38\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 146.9ms\n",
      "Speed: 2.1ms preprocess, 146.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "39\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 145.5ms\n",
      "Speed: 1.7ms preprocess, 145.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "40\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 159.3ms\n",
      "Speed: 2.0ms preprocess, 159.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "41\n",
      "\n",
      "0: 384x640 3 persons, 137.1ms\n",
      "Speed: 4.8ms preprocess, 137.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "42\n",
      "\n",
      "0: 384x640 3 persons, 136.0ms\n",
      "Speed: 2.4ms preprocess, 136.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "43\n",
      "\n",
      "0: 384x640 3 persons, 131.9ms\n",
      "Speed: 1.9ms preprocess, 131.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "44\n",
      "\n",
      "0: 384x640 3 persons, 132.3ms\n",
      "Speed: 2.0ms preprocess, 132.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "45\n",
      "\n",
      "0: 384x640 3 persons, 139.5ms\n",
      "Speed: 0.0ms preprocess, 139.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "46\n",
      "\n",
      "0: 384x640 3 persons, 134.7ms\n",
      "Speed: 1.9ms preprocess, 134.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "47\n",
      "\n",
      "0: 384x640 3 persons, 139.5ms\n",
      "Speed: 1.0ms preprocess, 139.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "48\n",
      "\n",
      "0: 384x640 3 persons, 144.2ms\n",
      "Speed: 2.1ms preprocess, 144.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "49\n",
      "\n",
      "0: 384x640 3 persons, 133.7ms\n",
      "Speed: 2.0ms preprocess, 133.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "50\n",
      "\n",
      "0: 384x640 3 persons, 152.5ms\n",
      "Speed: 1.1ms preprocess, 152.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "51\n",
      "\n",
      "0: 384x640 3 persons, 139.9ms\n",
      "Speed: 1.9ms preprocess, 139.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "52\n",
      "\n",
      "0: 384x640 3 persons, 137.7ms\n",
      "Speed: 1.7ms preprocess, 137.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "53\n",
      "\n",
      "0: 384x640 3 persons, 157.4ms\n",
      "Speed: 1.9ms preprocess, 157.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "54\n",
      "\n",
      "0: 384x640 3 persons, 144.2ms\n",
      "Speed: 2.0ms preprocess, 144.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "55\n",
      "\n",
      "0: 384x640 3 persons, 135.7ms\n",
      "Speed: 2.0ms preprocess, 135.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "56\n",
      "\n",
      "0: 384x640 3 persons, 130.0ms\n",
      "Speed: 2.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "57\n",
      "\n",
      "0: 384x640 3 persons, 131.9ms\n",
      "Speed: 1.0ms preprocess, 131.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "58\n",
      "\n",
      "0: 384x640 3 persons, 142.2ms\n",
      "Speed: 1.0ms preprocess, 142.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "59\n",
      "\n",
      "0: 384x640 3 persons, 148.0ms\n",
      "Speed: 2.0ms preprocess, 148.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "60\n",
      "\n",
      "0: 384x640 3 persons, 148.2ms\n",
      "Speed: 4.1ms preprocess, 148.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "61\n",
      "\n",
      "0: 384x640 3 persons, 129.7ms\n",
      "Speed: 2.0ms preprocess, 129.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "62\n",
      "\n",
      "0: 384x640 3 persons, 144.1ms\n",
      "Speed: 2.0ms preprocess, 144.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "63\n",
      "\n",
      "0: 384x640 3 persons, 1 handbag, 146.8ms\n",
      "Speed: 3.0ms preprocess, 146.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "64\n",
      "\n",
      "0: 384x640 3 persons, 141.8ms\n",
      "Speed: 1.9ms preprocess, 141.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "65\n",
      "\n",
      "0: 384x640 4 persons, 152.1ms\n",
      "Speed: 3.1ms preprocess, 152.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "66\n",
      "\n",
      "0: 384x640 3 persons, 142.4ms\n",
      "Speed: 2.0ms preprocess, 142.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "67\n",
      "\n",
      "0: 384x640 3 persons, 146.9ms\n",
      "Speed: 2.0ms preprocess, 146.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "68\n",
      "\n",
      "0: 384x640 3 persons, 158.8ms\n",
      "Speed: 0.0ms preprocess, 158.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "69\n",
      "\n",
      "0: 384x640 3 persons, 167.2ms\n",
      "Speed: 3.0ms preprocess, 167.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "70\n",
      "\n",
      "0: 384x640 3 persons, 140.0ms\n",
      "Speed: 1.0ms preprocess, 140.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "71\n",
      "\n",
      "0: 384x640 3 persons, 130.1ms\n",
      "Speed: 1.9ms preprocess, 130.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "72\n",
      "\n",
      "0: 384x640 3 persons, 135.3ms\n",
      "Speed: 2.0ms preprocess, 135.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "73\n",
      "\n",
      "0: 384x640 3 persons, 130.7ms\n",
      "Speed: 2.0ms preprocess, 130.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "74\n",
      "\n",
      "0: 384x640 3 persons, 149.4ms\n",
      "Speed: 1.9ms preprocess, 149.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "75\n",
      "\n",
      "0: 384x640 3 persons, 135.5ms\n",
      "Speed: 1.0ms preprocess, 135.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "76\n",
      "\n",
      "0: 384x640 3 persons, 144.9ms\n",
      "Speed: 2.0ms preprocess, 144.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "77\n",
      "\n",
      "0: 384x640 3 persons, 129.7ms\n",
      "Speed: 1.0ms preprocess, 129.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "78\n",
      "\n",
      "0: 384x640 3 persons, 137.0ms\n",
      "Speed: 2.2ms preprocess, 137.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "79\n",
      "\n",
      "0: 384x640 3 persons, 137.6ms\n",
      "Speed: 2.0ms preprocess, 137.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "80\n",
      "\n",
      "0: 384x640 3 persons, 143.4ms\n",
      "Speed: 2.0ms preprocess, 143.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "81\n",
      "\n",
      "0: 384x640 3 persons, 134.4ms\n",
      "Speed: 2.1ms preprocess, 134.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "82\n",
      "\n",
      "0: 384x640 4 persons, 153.6ms\n",
      "Speed: 1.0ms preprocess, 153.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "83\n",
      "\n",
      "0: 384x640 3 persons, 150.3ms\n",
      "Speed: 2.0ms preprocess, 150.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "84\n",
      "\n",
      "0: 384x640 3 persons, 130.5ms\n",
      "Speed: 2.0ms preprocess, 130.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "85\n",
      "\n",
      "0: 384x640 3 persons, 135.5ms\n",
      "Speed: 1.0ms preprocess, 135.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "86\n",
      "\n",
      "0: 384x640 3 persons, 133.7ms\n",
      "Speed: 1.5ms preprocess, 133.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "87\n",
      "\n",
      "0: 384x640 3 persons, 135.8ms\n",
      "Speed: 1.0ms preprocess, 135.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "88\n",
      "\n",
      "0: 384x640 3 persons, 128.0ms\n",
      "Speed: 2.5ms preprocess, 128.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "89\n",
      "\n",
      "0: 384x640 3 persons, 170.1ms\n",
      "Speed: 2.3ms preprocess, 170.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "90\n",
      "\n",
      "0: 384x640 3 persons, 143.5ms\n",
      "Speed: 2.0ms preprocess, 143.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "91\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 149.4ms\n",
      "Speed: 2.0ms preprocess, 149.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "92\n",
      "\n",
      "0: 384x640 3 persons, 138.1ms\n",
      "Speed: 5.0ms preprocess, 138.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "93\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 136.3ms\n",
      "Speed: 1.0ms preprocess, 136.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "94\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 137.8ms\n",
      "Speed: 3.0ms preprocess, 137.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "95\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 140.5ms\n",
      "Speed: 2.0ms preprocess, 140.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "96\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 150.5ms\n",
      "Speed: 4.0ms preprocess, 150.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "97\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 180.1ms\n",
      "Speed: 4.2ms preprocess, 180.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "98\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 137.8ms\n",
      "Speed: 2.0ms preprocess, 137.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "99\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 146.9ms\n",
      "Speed: 2.0ms preprocess, 146.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "100\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 145.9ms\n",
      "Speed: 2.0ms preprocess, 145.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "101\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 137.3ms\n",
      "Speed: 2.0ms preprocess, 137.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "102\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 131.2ms\n",
      "Speed: 2.0ms preprocess, 131.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "103\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 170.0ms\n",
      "Speed: 1.0ms preprocess, 170.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "104\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 145.5ms\n",
      "Speed: 2.0ms preprocess, 145.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "105\n",
      "\n",
      "0: 384x640 3 persons, 140.0ms\n",
      "Speed: 3.0ms preprocess, 140.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "106\n",
      "\n",
      "0: 384x640 3 persons, 138.2ms\n",
      "Speed: 4.0ms preprocess, 138.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "107\n",
      "\n",
      "0: 384x640 3 persons, 154.0ms\n",
      "Speed: 0.9ms preprocess, 154.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "108\n",
      "\n",
      "0: 384x640 3 persons, 137.5ms\n",
      "Speed: 2.0ms preprocess, 137.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "109\n",
      "\n",
      "0: 384x640 3 persons, 131.2ms\n",
      "Speed: 2.1ms preprocess, 131.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "110\n",
      "\n",
      "0: 384x640 3 persons, 142.2ms\n",
      "Speed: 2.9ms preprocess, 142.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "111\n",
      "\n",
      "0: 384x640 3 persons, 158.9ms\n",
      "Speed: 1.9ms preprocess, 158.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "112\n",
      "\n",
      "0: 384x640 3 persons, 162.7ms\n",
      "Speed: 1.6ms preprocess, 162.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "113\n",
      "\n",
      "0: 384x640 3 persons, 140.1ms\n",
      "Speed: 1.0ms preprocess, 140.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "114\n",
      "\n",
      "0: 384x640 3 persons, 174.7ms\n",
      "Speed: 1.8ms preprocess, 174.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "115\n",
      "\n",
      "0: 384x640 4 persons, 151.1ms\n",
      "Speed: 2.0ms preprocess, 151.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "116\n",
      "\n",
      "0: 384x640 3 persons, 141.7ms\n",
      "Speed: 2.1ms preprocess, 141.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "117\n",
      "\n",
      "0: 384x640 3 persons, 156.2ms\n",
      "Speed: 1.0ms preprocess, 156.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "118\n",
      "\n",
      "0: 384x640 4 persons, 148.0ms\n",
      "Speed: 2.2ms preprocess, 148.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "119\n",
      "\n",
      "0: 384x640 4 persons, 144.4ms\n",
      "Speed: 2.7ms preprocess, 144.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "120\n",
      "\n",
      "0: 384x640 4 persons, 142.9ms\n",
      "Speed: 2.0ms preprocess, 142.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "121\n",
      "\n",
      "0: 384x640 4 persons, 130.3ms\n",
      "Speed: 4.7ms preprocess, 130.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "122\n",
      "\n",
      "0: 384x640 3 persons, 139.2ms\n",
      "Speed: 4.9ms preprocess, 139.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "123\n",
      "\n",
      "0: 384x640 3 persons, 145.1ms\n",
      "Speed: 1.6ms preprocess, 145.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "124\n",
      "\n",
      "0: 384x640 3 persons, 137.2ms\n",
      "Speed: 2.0ms preprocess, 137.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "125\n",
      "\n",
      "0: 384x640 4 persons, 143.8ms\n",
      "Speed: 2.0ms preprocess, 143.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "126\n",
      "\n",
      "0: 384x640 3 persons, 145.8ms\n",
      "Speed: 2.0ms preprocess, 145.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "127\n",
      "\n",
      "0: 384x640 3 persons, 139.9ms\n",
      "Speed: 3.0ms preprocess, 139.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "128\n",
      "\n",
      "0: 384x640 3 persons, 136.5ms\n",
      "Speed: 1.0ms preprocess, 136.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "129\n",
      "\n",
      "0: 384x640 3 persons, 144.3ms\n",
      "Speed: 1.0ms preprocess, 144.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "130\n",
      "\n",
      "0: 384x640 3 persons, 134.0ms\n",
      "Speed: 3.3ms preprocess, 134.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "131\n",
      "\n",
      "0: 384x640 3 persons, 142.3ms\n",
      "Speed: 1.0ms preprocess, 142.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "132\n",
      "\n",
      "0: 384x640 3 persons, 135.5ms\n",
      "Speed: 2.0ms preprocess, 135.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "133\n",
      "\n",
      "0: 384x640 4 persons, 136.5ms\n",
      "Speed: 2.0ms preprocess, 136.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "134\n",
      "\n",
      "0: 384x640 4 persons, 136.4ms\n",
      "Speed: 2.5ms preprocess, 136.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "135\n",
      "\n",
      "0: 384x640 4 persons, 137.4ms\n",
      "Speed: 2.4ms preprocess, 137.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "136\n",
      "\n",
      "0: 384x640 3 persons, 132.2ms\n",
      "Speed: 1.5ms preprocess, 132.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "137\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 141.1ms\n",
      "Speed: 2.0ms preprocess, 141.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "138\n",
      "\n",
      "0: 384x640 3 persons, 137.3ms\n",
      "Speed: 1.9ms preprocess, 137.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "139\n",
      "\n",
      "0: 384x640 3 persons, 130.8ms\n",
      "Speed: 2.0ms preprocess, 130.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "140\n",
      "\n",
      "0: 384x640 4 persons, 134.1ms\n",
      "Speed: 1.0ms preprocess, 134.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "141\n",
      "\n",
      "0: 384x640 3 persons, 136.1ms\n",
      "Speed: 2.5ms preprocess, 136.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "142\n",
      "\n",
      "0: 384x640 3 persons, 151.4ms\n",
      "Speed: 2.1ms preprocess, 151.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "143\n",
      "\n",
      "0: 384x640 3 persons, 136.6ms\n",
      "Speed: 3.0ms preprocess, 136.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "144\n",
      "\n",
      "0: 384x640 3 persons, 137.7ms\n",
      "Speed: 2.0ms preprocess, 137.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "145\n",
      "\n",
      "0: 384x640 3 persons, 145.1ms\n",
      "Speed: 2.2ms preprocess, 145.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "146\n",
      "\n",
      "0: 384x640 3 persons, 140.0ms\n",
      "Speed: 2.0ms preprocess, 140.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "147\n",
      "\n",
      "0: 384x640 3 persons, 133.1ms\n",
      "Speed: 2.0ms preprocess, 133.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "148\n",
      "\n",
      "0: 384x640 3 persons, 149.5ms\n",
      "Speed: 2.0ms preprocess, 149.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "149\n",
      "\n",
      "0: 384x640 3 persons, 146.3ms\n",
      "Speed: 1.0ms preprocess, 146.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "150\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 156.4ms\n",
      "Speed: 2.0ms preprocess, 156.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "151\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 153.5ms\n",
      "Speed: 1.0ms preprocess, 153.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "152\n",
      "\n",
      "0: 384x640 2 persons, 145.9ms\n",
      "Speed: 2.0ms preprocess, 145.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "153\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 129.4ms\n",
      "Speed: 0.9ms preprocess, 129.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "154\n",
      "\n",
      "0: 384x640 2 persons, 140.0ms\n",
      "Speed: 2.0ms preprocess, 140.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "155\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 138.4ms\n",
      "Speed: 2.0ms preprocess, 138.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "156\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 146.5ms\n",
      "Speed: 2.0ms preprocess, 146.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "157\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 150.2ms\n",
      "Speed: 2.0ms preprocess, 150.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "158\n",
      "\n",
      "0: 384x640 3 persons, 145.2ms\n",
      "Speed: 1.0ms preprocess, 145.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "159\n",
      "\n",
      "0: 384x640 3 persons, 135.6ms\n",
      "Speed: 2.0ms preprocess, 135.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "160\n",
      "\n",
      "0: 384x640 3 persons, 151.6ms\n",
      "Speed: 2.1ms preprocess, 151.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "161\n",
      "\n",
      "0: 384x640 3 persons, 152.6ms\n",
      "Speed: 2.0ms preprocess, 152.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "162\n",
      "\n",
      "0: 384x640 3 persons, 133.1ms\n",
      "Speed: 1.0ms preprocess, 133.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "163\n",
      "\n",
      "0: 384x640 2 persons, 1 traffic light, 151.7ms\n",
      "Speed: 2.7ms preprocess, 151.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "164\n",
      "\n",
      "0: 384x640 3 persons, 144.0ms\n",
      "Speed: 1.5ms preprocess, 144.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "165\n",
      "\n",
      "0: 384x640 2 persons, 135.8ms\n",
      "Speed: 2.0ms preprocess, 135.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "166\n",
      "\n",
      "0: 384x640 2 persons, 139.6ms\n",
      "Speed: 0.9ms preprocess, 139.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "167\n",
      "\n",
      "0: 384x640 2 persons, 137.5ms\n",
      "Speed: 2.0ms preprocess, 137.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "168\n",
      "\n",
      "0: 384x640 2 persons, 153.3ms\n",
      "Speed: 1.0ms preprocess, 153.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "169\n",
      "\n",
      "0: 384x640 2 persons, 151.1ms\n",
      "Speed: 3.0ms preprocess, 151.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "170\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 134.7ms\n",
      "Speed: 2.0ms preprocess, 134.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "171\n",
      "\n",
      "0: 384x640 2 persons, 143.0ms\n",
      "Speed: 1.4ms preprocess, 143.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "172\n",
      "\n",
      "0: 384x640 2 persons, 138.1ms\n",
      "Speed: 2.0ms preprocess, 138.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "173\n",
      "\n",
      "0: 384x640 2 persons, 141.6ms\n",
      "Speed: 2.0ms preprocess, 141.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "174\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 138.1ms\n",
      "Speed: 2.0ms preprocess, 138.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "175\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 142.5ms\n",
      "Speed: 2.0ms preprocess, 142.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "176\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 145.2ms\n",
      "Speed: 2.0ms preprocess, 145.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "177\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 137.2ms\n",
      "Speed: 2.2ms preprocess, 137.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "178\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 133.8ms\n",
      "Speed: 2.0ms preprocess, 133.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "179\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 146.8ms\n",
      "Speed: 2.0ms preprocess, 146.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "180\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 151.8ms\n",
      "Speed: 2.0ms preprocess, 151.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "181\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 128.5ms\n",
      "Speed: 2.0ms preprocess, 128.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "182\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 143.9ms\n",
      "Speed: 2.0ms preprocess, 143.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "183\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 143.1ms\n",
      "Speed: 1.4ms preprocess, 143.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "184\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 141.6ms\n",
      "Speed: 2.0ms preprocess, 141.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "185\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 151.2ms\n",
      "Speed: 2.0ms preprocess, 151.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "186\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 184.8ms\n",
      "Speed: 2.0ms preprocess, 184.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "187\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 143.2ms\n",
      "Speed: 2.0ms preprocess, 143.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "188\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 133.4ms\n",
      "Speed: 2.0ms preprocess, 133.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "189\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 139.3ms\n",
      "Speed: 2.0ms preprocess, 139.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "190\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 147.8ms\n",
      "Speed: 3.0ms preprocess, 147.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "191\n",
      "\n",
      "0: 384x640 2 persons, 142.3ms\n",
      "Speed: 2.6ms preprocess, 142.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "192\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 142.6ms\n",
      "Speed: 1.0ms preprocess, 142.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "193\n",
      "\n",
      "0: 384x640 2 persons, 134.4ms\n",
      "Speed: 2.4ms preprocess, 134.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "194\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 145.9ms\n",
      "Speed: 2.0ms preprocess, 145.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "195\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 134.4ms\n",
      "Speed: 2.0ms preprocess, 134.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "196\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 135.6ms\n",
      "Speed: 2.0ms preprocess, 135.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "197\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 129.1ms\n",
      "Speed: 1.8ms preprocess, 129.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "198\n",
      "\n",
      "0: 384x640 2 persons, 147.6ms\n",
      "Speed: 2.0ms preprocess, 147.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "199\n",
      "\n",
      "0: 384x640 2 persons, 143.7ms\n",
      "Speed: 2.0ms preprocess, 143.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "200\n",
      "\n",
      "0: 384x640 2 persons, 170.6ms\n",
      "Speed: 2.0ms preprocess, 170.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "201\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 133.5ms\n",
      "Speed: 1.0ms preprocess, 133.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "202\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 148.3ms\n",
      "Speed: 2.4ms preprocess, 148.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "203\n",
      "\n",
      "0: 384x640 2 persons, 140.6ms\n",
      "Speed: 2.0ms preprocess, 140.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "204\n",
      "\n",
      "0: 384x640 2 persons, 142.0ms\n",
      "Speed: 1.9ms preprocess, 142.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "205\n",
      "\n",
      "0: 384x640 2 persons, 156.6ms\n",
      "Speed: 3.0ms preprocess, 156.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "206\n",
      "\n",
      "0: 384x640 2 persons, 136.8ms\n",
      "Speed: 3.5ms preprocess, 136.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "207\n",
      "\n",
      "0: 384x640 2 persons, 135.4ms\n",
      "Speed: 2.0ms preprocess, 135.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "208\n",
      "\n",
      "0: 384x640 2 persons, 154.1ms\n",
      "Speed: 2.0ms preprocess, 154.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "209\n",
      "\n",
      "0: 384x640 2 persons, 137.9ms\n",
      "Speed: 1.0ms preprocess, 137.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "210\n",
      "\n",
      "0: 384x640 2 persons, 146.8ms\n",
      "Speed: 3.1ms preprocess, 146.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "211\n",
      "\n",
      "0: 384x640 2 persons, 141.2ms\n",
      "Speed: 2.0ms preprocess, 141.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "212\n",
      "\n",
      "0: 384x640 2 persons, 134.9ms\n",
      "Speed: 3.0ms preprocess, 134.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "213\n",
      "\n",
      "0: 384x640 2 persons, 142.9ms\n",
      "Speed: 2.0ms preprocess, 142.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "214\n",
      "\n",
      "0: 384x640 2 persons, 154.8ms\n",
      "Speed: 3.0ms preprocess, 154.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "215\n",
      "\n",
      "0: 384x640 2 persons, 144.0ms\n",
      "Speed: 2.0ms preprocess, 144.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "216\n",
      "\n",
      "0: 384x640 2 persons, 145.8ms\n",
      "Speed: 3.0ms preprocess, 145.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "217\n",
      "\n",
      "0: 384x640 2 persons, 144.4ms\n",
      "Speed: 2.0ms preprocess, 144.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "218\n",
      "\n",
      "0: 384x640 2 persons, 140.1ms\n",
      "Speed: 1.0ms preprocess, 140.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "219\n",
      "\n",
      "0: 384x640 2 persons, 140.3ms\n",
      "Speed: 1.5ms preprocess, 140.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "220\n",
      "\n",
      "0: 384x640 2 persons, 139.8ms\n",
      "Speed: 1.0ms preprocess, 139.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "221\n",
      "\n",
      "0: 384x640 2 persons, 141.8ms\n",
      "Speed: 2.0ms preprocess, 141.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "222\n",
      "\n",
      "0: 384x640 2 persons, 141.6ms\n",
      "Speed: 2.6ms preprocess, 141.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "223\n",
      "\n",
      "0: 384x640 2 persons, 154.1ms\n",
      "Speed: 1.2ms preprocess, 154.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "224\n",
      "\n",
      "0: 384x640 2 persons, 142.9ms\n",
      "Speed: 1.0ms preprocess, 142.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "225\n",
      "\n",
      "0: 384x640 2 persons, 140.2ms\n",
      "Speed: 2.0ms preprocess, 140.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "226\n",
      "\n",
      "0: 384x640 2 persons, 142.2ms\n",
      "Speed: 2.0ms preprocess, 142.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "227\n",
      "\n",
      "0: 384x640 2 persons, 142.1ms\n",
      "Speed: 2.0ms preprocess, 142.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "228\n",
      "\n",
      "0: 384x640 2 persons, 138.3ms\n",
      "Speed: 2.0ms preprocess, 138.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "229\n",
      "\n",
      "0: 384x640 2 persons, 138.9ms\n",
      "Speed: 2.0ms preprocess, 138.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "230\n",
      "\n",
      "0: 384x640 2 persons, 131.8ms\n",
      "Speed: 1.9ms preprocess, 131.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "231\n",
      "\n",
      "0: 384x640 2 persons, 140.7ms\n",
      "Speed: 2.0ms preprocess, 140.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "232\n",
      "\n",
      "0: 384x640 2 persons, 138.7ms\n",
      "Speed: 2.1ms preprocess, 138.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "233\n",
      "\n",
      "0: 384x640 2 persons, 140.2ms\n",
      "Speed: 1.0ms preprocess, 140.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "234\n",
      "\n",
      "0: 384x640 2 persons, 144.6ms\n",
      "Speed: 2.0ms preprocess, 144.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "235\n",
      "\n",
      "0: 384x640 2 persons, 143.8ms\n",
      "Speed: 2.3ms preprocess, 143.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "236\n",
      "\n",
      "0: 384x640 2 persons, 151.1ms\n",
      "Speed: 2.0ms preprocess, 151.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "237\n",
      "\n",
      "0: 384x640 3 persons, 155.8ms\n",
      "Speed: 2.0ms preprocess, 155.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "238\n",
      "\n",
      "0: 384x640 2 persons, 138.4ms\n",
      "Speed: 2.0ms preprocess, 138.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "239\n",
      "\n",
      "0: 384x640 2 persons, 141.7ms\n",
      "Speed: 1.9ms preprocess, 141.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "240\n",
      "\n",
      "0: 384x640 2 persons, 137.3ms\n",
      "Speed: 1.0ms preprocess, 137.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "241\n",
      "\n",
      "0: 384x640 2 persons, 155.2ms\n",
      "Speed: 2.1ms preprocess, 155.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "242\n",
      "\n",
      "0: 384x640 2 persons, 141.7ms\n",
      "Speed: 1.0ms preprocess, 141.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "243\n",
      "\n",
      "0: 384x640 2 persons, 139.8ms\n",
      "Speed: 2.0ms preprocess, 139.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "244\n",
      "\n",
      "0: 384x640 2 persons, 142.5ms\n",
      "Speed: 2.0ms preprocess, 142.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "245\n",
      "\n",
      "0: 384x640 2 persons, 170.6ms\n",
      "Speed: 2.0ms preprocess, 170.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "246\n",
      "\n",
      "0: 384x640 2 persons, 151.2ms\n",
      "Speed: 2.0ms preprocess, 151.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "247\n",
      "\n",
      "0: 384x640 2 persons, 141.9ms\n",
      "Speed: 2.0ms preprocess, 141.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "248\n",
      "\n",
      "0: 384x640 2 persons, 161.9ms\n",
      "Speed: 1.9ms preprocess, 161.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "249\n",
      "\n",
      "0: 384x640 2 persons, 164.4ms\n",
      "Speed: 3.0ms preprocess, 164.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "250\n",
      "\n",
      "0: 384x640 2 persons, 155.1ms\n",
      "Speed: 2.0ms preprocess, 155.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "251\n",
      "\n",
      "0: 384x640 2 persons, 145.5ms\n",
      "Speed: 1.0ms preprocess, 145.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "252\n",
      "\n",
      "0: 384x640 2 persons, 146.8ms\n",
      "Speed: 3.0ms preprocess, 146.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "253\n",
      "\n",
      "0: 384x640 2 persons, 148.5ms\n",
      "Speed: 3.0ms preprocess, 148.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "254\n",
      "\n",
      "0: 384x640 2 persons, 161.5ms\n",
      "Speed: 2.0ms preprocess, 161.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "255\n",
      "\n",
      "0: 384x640 2 persons, 150.2ms\n",
      "Speed: 2.0ms preprocess, 150.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "256\n",
      "\n",
      "0: 384x640 2 persons, 139.1ms\n",
      "Speed: 1.4ms preprocess, 139.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "257\n",
      "\n",
      "0: 384x640 2 persons, 142.0ms\n",
      "Speed: 2.0ms preprocess, 142.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "258\n",
      "\n",
      "0: 384x640 2 persons, 150.3ms\n",
      "Speed: 2.0ms preprocess, 150.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "259\n",
      "\n",
      "0: 384x640 2 persons, 137.9ms\n",
      "Speed: 1.6ms preprocess, 137.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "260\n",
      "\n",
      "0: 384x640 2 persons, 139.6ms\n",
      "Speed: 1.0ms preprocess, 139.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "261\n",
      "\n",
      "0: 384x640 2 persons, 136.5ms\n",
      "Speed: 1.8ms preprocess, 136.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "262\n",
      "\n",
      "0: 384x640 2 persons, 138.4ms\n",
      "Speed: 1.8ms preprocess, 138.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "263\n",
      "\n",
      "0: 384x640 2 persons, 157.8ms\n",
      "Speed: 2.1ms preprocess, 157.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "264\n",
      "\n",
      "0: 384x640 2 persons, 172.0ms\n",
      "Speed: 1.9ms preprocess, 172.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "265\n",
      "\n",
      "0: 384x640 2 persons, 149.1ms\n",
      "Speed: 3.0ms preprocess, 149.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "266\n",
      "\n",
      "0: 384x640 2 persons, 145.8ms\n",
      "Speed: 2.7ms preprocess, 145.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "267\n",
      "\n",
      "0: 384x640 2 persons, 137.1ms\n",
      "Speed: 2.8ms preprocess, 137.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "268\n",
      "\n",
      "0: 384x640 3 persons, 169.8ms\n",
      "Speed: 2.5ms preprocess, 169.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "269\n",
      "\n",
      "0: 384x640 3 persons, 173.3ms\n",
      "Speed: 2.1ms preprocess, 173.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "270\n",
      "\n",
      "0: 384x640 3 persons, 144.0ms\n",
      "Speed: 2.0ms preprocess, 144.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "271\n",
      "\n",
      "0: 384x640 2 persons, 137.2ms\n",
      "Speed: 2.0ms preprocess, 137.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "272\n",
      "\n",
      "0: 384x640 3 persons, 148.8ms\n",
      "Speed: 1.0ms preprocess, 148.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "273\n",
      "\n",
      "0: 384x640 3 persons, 170.4ms\n",
      "Speed: 2.0ms preprocess, 170.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "274\n",
      "\n",
      "0: 384x640 2 persons, 150.6ms\n",
      "Speed: 3.0ms preprocess, 150.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "275\n",
      "\n",
      "0: 384x640 2 persons, 139.8ms\n",
      "Speed: 4.4ms preprocess, 139.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "276\n",
      "\n",
      "0: 384x640 2 persons, 139.9ms\n",
      "Speed: 2.0ms preprocess, 139.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "277\n",
      "\n",
      "0: 384x640 2 persons, 141.2ms\n",
      "Speed: 2.2ms preprocess, 141.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "278\n",
      "\n",
      "0: 384x640 2 persons, 151.2ms\n",
      "Speed: 1.9ms preprocess, 151.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "279\n",
      "\n",
      "0: 384x640 2 persons, 150.1ms\n",
      "Speed: 2.0ms preprocess, 150.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "280\n",
      "\n",
      "0: 384x640 2 persons, 144.9ms\n",
      "Speed: 2.1ms preprocess, 144.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "281\n",
      "\n",
      "0: 384x640 2 persons, 144.9ms\n",
      "Speed: 2.0ms preprocess, 144.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "282\n",
      "\n",
      "0: 384x640 2 persons, 152.1ms\n",
      "Speed: 2.0ms preprocess, 152.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "283\n",
      "\n",
      "0: 384x640 2 persons, 134.3ms\n",
      "Speed: 2.0ms preprocess, 134.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "284\n",
      "\n",
      "0: 384x640 2 persons, 150.0ms\n",
      "Speed: 2.0ms preprocess, 150.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "285\n",
      "\n",
      "0: 384x640 2 persons, 138.1ms\n",
      "Speed: 3.0ms preprocess, 138.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "286\n",
      "\n",
      "0: 384x640 2 persons, 141.1ms\n",
      "Speed: 3.0ms preprocess, 141.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "287\n",
      "\n",
      "0: 384x640 2 persons, 158.8ms\n",
      "Speed: 1.9ms preprocess, 158.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "288\n",
      "\n",
      "0: 384x640 2 persons, 149.3ms\n",
      "Speed: 2.0ms preprocess, 149.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "289\n",
      "\n",
      "0: 384x640 2 persons, 139.9ms\n",
      "Speed: 2.0ms preprocess, 139.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "290\n",
      "\n",
      "0: 384x640 2 persons, 156.1ms\n",
      "Speed: 2.0ms preprocess, 156.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "291\n",
      "\n",
      "0: 384x640 2 persons, 129.5ms\n",
      "Speed: 2.0ms preprocess, 129.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "292\n",
      "\n",
      "0: 384x640 2 persons, 171.5ms\n",
      "Speed: 2.0ms preprocess, 171.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "293\n",
      "\n",
      "0: 384x640 2 persons, 140.6ms\n",
      "Speed: 2.4ms preprocess, 140.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "294\n",
      "\n",
      "0: 384x640 2 persons, 149.0ms\n",
      "Speed: 2.0ms preprocess, 149.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "295\n",
      "\n",
      "0: 384x640 2 persons, 158.2ms\n",
      "Speed: 2.9ms preprocess, 158.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "296\n",
      "\n",
      "0: 384x640 2 persons, 161.0ms\n",
      "Speed: 2.0ms preprocess, 161.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "297\n",
      "\n",
      "0: 384x640 2 persons, 138.7ms\n",
      "Speed: 2.0ms preprocess, 138.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "298\n",
      "\n",
      "0: 384x640 2 persons, 142.3ms\n",
      "Speed: 2.3ms preprocess, 142.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "299\n",
      "\n",
      "0: 384x640 1 person, 146.1ms\n",
      "Speed: 2.0ms preprocess, 146.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "300\n",
      "\n",
      "0: 384x640 1 person, 129.3ms\n",
      "Speed: 2.0ms preprocess, 129.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "301\n",
      "\n",
      "0: 384x640 1 person, 174.3ms\n",
      "Speed: 1.8ms preprocess, 174.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "302\n",
      "\n",
      "0: 384x640 1 person, 149.1ms\n",
      "Speed: 2.0ms preprocess, 149.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "303\n",
      "\n",
      "0: 384x640 1 person, 138.8ms\n",
      "Speed: 2.0ms preprocess, 138.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "304\n",
      "\n",
      "0: 384x640 1 person, 140.7ms\n",
      "Speed: 2.9ms preprocess, 140.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "305\n",
      "\n",
      "0: 384x640 3 persons, 167.4ms\n",
      "Speed: 1.0ms preprocess, 167.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "306\n",
      "\n",
      "0: 384x640 2 persons, 138.3ms\n",
      "Speed: 1.7ms preprocess, 138.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "307\n",
      "\n",
      "0: 384x640 2 persons, 142.1ms\n",
      "Speed: 2.0ms preprocess, 142.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "308\n",
      "\n",
      "0: 384x640 2 persons, 162.7ms\n",
      "Speed: 2.0ms preprocess, 162.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "309\n",
      "\n",
      "0: 384x640 2 persons, 136.7ms\n",
      "Speed: 3.1ms preprocess, 136.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "310\n",
      "\n",
      "0: 384x640 2 persons, 133.3ms\n",
      "Speed: 3.1ms preprocess, 133.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "311\n",
      "\n",
      "0: 384x640 2 persons, 134.9ms\n",
      "Speed: 2.0ms preprocess, 134.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "312\n",
      "\n",
      "0: 384x640 2 persons, 156.5ms\n",
      "Speed: 1.0ms preprocess, 156.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "313\n",
      "\n",
      "0: 384x640 2 persons, 131.9ms\n",
      "Speed: 2.0ms preprocess, 131.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "314\n",
      "\n",
      "0: 384x640 2 persons, 138.3ms\n",
      "Speed: 3.1ms preprocess, 138.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "315\n",
      "\n",
      "0: 384x640 2 persons, 137.4ms\n",
      "Speed: 1.0ms preprocess, 137.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "316\n",
      "\n",
      "0: 384x640 2 persons, 181.0ms\n",
      "Speed: 2.4ms preprocess, 181.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "317\n",
      "\n",
      "0: 384x640 2 persons, 157.6ms\n",
      "Speed: 1.5ms preprocess, 157.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "318\n",
      "\n",
      "0: 384x640 2 persons, 170.2ms\n",
      "Speed: 2.0ms preprocess, 170.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "319\n",
      "\n",
      "0: 384x640 2 persons, 158.7ms\n",
      "Speed: 3.3ms preprocess, 158.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "320\n",
      "\n",
      "0: 384x640 2 persons, 155.4ms\n",
      "Speed: 2.0ms preprocess, 155.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "321\n",
      "\n",
      "0: 384x640 2 persons, 150.0ms\n",
      "Speed: 2.0ms preprocess, 150.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "322\n",
      "\n",
      "0: 384x640 2 persons, 141.5ms\n",
      "Speed: 2.0ms preprocess, 141.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "323\n",
      "\n",
      "0: 384x640 3 persons, 177.6ms\n",
      "Speed: 2.0ms preprocess, 177.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "324\n",
      "\n",
      "0: 384x640 2 persons, 136.1ms\n",
      "Speed: 4.0ms preprocess, 136.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "325\n",
      "\n",
      "0: 384x640 2 persons, 141.9ms\n",
      "Speed: 3.0ms preprocess, 141.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "326\n",
      "\n",
      "0: 384x640 2 persons, 151.1ms\n",
      "Speed: 3.0ms preprocess, 151.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "327\n",
      "\n",
      "0: 384x640 3 persons, 139.2ms\n",
      "Speed: 1.7ms preprocess, 139.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "328\n",
      "\n",
      "0: 384x640 3 persons, 167.7ms\n",
      "Speed: 2.0ms preprocess, 167.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "329\n",
      "\n",
      "0: 384x640 3 persons, 140.2ms\n",
      "Speed: 2.3ms preprocess, 140.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "330\n",
      "\n",
      "0: 384x640 3 persons, 157.7ms\n",
      "Speed: 2.1ms preprocess, 157.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "331\n",
      "\n",
      "0: 384x640 3 persons, 148.1ms\n",
      "Speed: 1.3ms preprocess, 148.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "332\n",
      "\n",
      "0: 384x640 3 persons, 134.4ms\n",
      "Speed: 3.4ms preprocess, 134.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "333\n",
      "\n",
      "0: 384x640 2 persons, 159.3ms\n",
      "Speed: 2.0ms preprocess, 159.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "334\n",
      "\n",
      "0: 384x640 2 persons, 132.4ms\n",
      "Speed: 2.4ms preprocess, 132.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "335\n",
      "\n",
      "0: 384x640 2 persons, 143.1ms\n",
      "Speed: 3.0ms preprocess, 143.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "336\n",
      "\n",
      "0: 384x640 2 persons, 178.2ms\n",
      "Speed: 1.1ms preprocess, 178.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "337\n",
      "\n",
      "0: 384x640 2 persons, 138.3ms\n",
      "Speed: 2.0ms preprocess, 138.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "338\n",
      "\n",
      "0: 384x640 3 persons, 124.1ms\n",
      "Speed: 2.0ms preprocess, 124.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "339\n",
      "\n",
      "0: 384x640 2 persons, 169.0ms\n",
      "Speed: 1.0ms preprocess, 169.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "340\n",
      "\n",
      "0: 384x640 3 persons, 165.4ms\n",
      "Speed: 3.0ms preprocess, 165.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "341\n",
      "\n",
      "0: 384x640 2 persons, 158.5ms\n",
      "Speed: 2.0ms preprocess, 158.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "342\n",
      "\n",
      "0: 384x640 2 persons, 134.6ms\n",
      "Speed: 2.0ms preprocess, 134.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "343\n",
      "\n",
      "0: 384x640 2 persons, 159.8ms\n",
      "Speed: 2.2ms preprocess, 159.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "344\n",
      "\n",
      "0: 384x640 2 persons, 158.6ms\n",
      "Speed: 2.0ms preprocess, 158.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "345\n",
      "\n",
      "0: 384x640 2 persons, 137.0ms\n",
      "Speed: 2.0ms preprocess, 137.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "346\n",
      "\n",
      "0: 384x640 2 persons, 137.9ms\n",
      "Speed: 2.0ms preprocess, 137.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "347\n",
      "\n",
      "0: 384x640 2 persons, 150.7ms\n",
      "Speed: 1.9ms preprocess, 150.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "348\n",
      "\n",
      "0: 384x640 2 persons, 148.1ms\n",
      "Speed: 2.4ms preprocess, 148.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "349\n",
      "\n",
      "0: 384x640 2 persons, 153.1ms\n",
      "Speed: 3.9ms preprocess, 153.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "350\n",
      "\n",
      "0: 384x640 2 persons, 146.0ms\n",
      "Speed: 2.0ms preprocess, 146.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "351\n",
      "\n",
      "0: 384x640 2 persons, 146.8ms\n",
      "Speed: 2.0ms preprocess, 146.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "352\n",
      "\n",
      "0: 384x640 2 persons, 163.4ms\n",
      "Speed: 2.0ms preprocess, 163.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "353\n",
      "\n",
      "0: 384x640 1 person, 154.8ms\n",
      "Speed: 2.0ms preprocess, 154.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "354\n",
      "\n",
      "0: 384x640 1 person, 146.9ms\n",
      "Speed: 2.0ms preprocess, 146.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "355\n",
      "\n",
      "0: 384x640 1 person, 140.2ms\n",
      "Speed: 1.9ms preprocess, 140.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "356\n",
      "\n",
      "0: 384x640 1 person, 168.5ms\n",
      "Speed: 3.0ms preprocess, 168.5ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "357\n",
      "\n",
      "0: 384x640 1 person, 158.9ms\n",
      "Speed: 2.0ms preprocess, 158.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "358\n",
      "\n",
      "0: 384x640 1 person, 148.7ms\n",
      "Speed: 2.0ms preprocess, 148.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "359\n",
      "\n",
      "0: 384x640 1 person, 167.0ms\n",
      "Speed: 1.5ms preprocess, 167.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "360\n",
      "\n",
      "0: 384x640 2 persons, 137.1ms\n",
      "Speed: 2.0ms preprocess, 137.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "361\n",
      "\n",
      "0: 384x640 2 persons, 181.0ms\n",
      "Speed: 2.0ms preprocess, 181.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "362\n",
      "\n",
      "0: 384x640 2 persons, 199.1ms\n",
      "Speed: 2.0ms preprocess, 199.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "363\n",
      "\n",
      "0: 384x640 2 persons, 164.6ms\n",
      "Speed: 1.6ms preprocess, 164.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "364\n",
      "\n",
      "0: 384x640 2 persons, 139.4ms\n",
      "Speed: 1.0ms preprocess, 139.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "365\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 142.1ms\n",
      "Speed: 2.0ms preprocess, 142.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "366\n",
      "\n",
      "0: 384x640 2 persons, 148.0ms\n",
      "Speed: 1.1ms preprocess, 148.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "367\n",
      "\n",
      "0: 384x640 2 persons, 130.7ms\n",
      "Speed: 3.0ms preprocess, 130.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "368\n",
      "\n",
      "0: 384x640 2 persons, 153.0ms\n",
      "Speed: 3.0ms preprocess, 153.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "369\n",
      "\n",
      "0: 384x640 2 persons, 138.0ms\n",
      "Speed: 2.0ms preprocess, 138.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "370\n",
      "\n",
      "0: 384x640 2 persons, 171.9ms\n",
      "Speed: 2.1ms preprocess, 171.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "371\n",
      "\n",
      "0: 384x640 2 persons, 146.5ms\n",
      "Speed: 2.4ms preprocess, 146.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "372\n",
      "\n",
      "0: 384x640 2 persons, 155.1ms\n",
      "Speed: 2.0ms preprocess, 155.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "373\n",
      "\n",
      "0: 384x640 2 persons, 158.6ms\n",
      "Speed: 1.9ms preprocess, 158.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "374\n",
      "\n",
      "0: 384x640 3 persons, 153.4ms\n",
      "Speed: 2.0ms preprocess, 153.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "375\n",
      "\n",
      "0: 384x640 2 persons, 172.7ms\n",
      "Speed: 2.0ms preprocess, 172.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "376\n",
      "\n",
      "0: 384x640 2 persons, 131.6ms\n",
      "Speed: 4.3ms preprocess, 131.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "377\n",
      "\n",
      "0: 384x640 2 persons, 132.1ms\n",
      "Speed: 3.5ms preprocess, 132.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "378\n",
      "\n",
      "0: 384x640 2 persons, 134.9ms\n",
      "Speed: 2.0ms preprocess, 134.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "379\n",
      "\n",
      "0: 384x640 2 persons, 154.5ms\n",
      "Speed: 1.8ms preprocess, 154.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "380\n",
      "\n",
      "0: 384x640 2 persons, 140.5ms\n",
      "Speed: 2.0ms preprocess, 140.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "381\n",
      "\n",
      "0: 384x640 2 persons, 159.6ms\n",
      "Speed: 1.0ms preprocess, 159.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "382\n",
      "\n",
      "0: 384x640 2 persons, 138.7ms\n",
      "Speed: 2.0ms preprocess, 138.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "383\n",
      "\n",
      "0: 384x640 2 persons, 150.9ms\n",
      "Speed: 2.0ms preprocess, 150.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "384\n",
      "\n",
      "0: 384x640 2 persons, 134.7ms\n",
      "Speed: 1.5ms preprocess, 134.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "385\n",
      "\n",
      "0: 384x640 2 persons, 136.5ms\n",
      "Speed: 2.0ms preprocess, 136.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "386\n",
      "\n",
      "0: 384x640 2 persons, 149.4ms\n",
      "Speed: 2.0ms preprocess, 149.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "387\n",
      "\n",
      "0: 384x640 2 persons, 151.8ms\n",
      "Speed: 2.1ms preprocess, 151.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "388\n",
      "\n",
      "0: 384x640 2 persons, 144.3ms\n",
      "Speed: 2.0ms preprocess, 144.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "389\n",
      "\n",
      "0: 384x640 2 persons, 133.6ms\n",
      "Speed: 2.2ms preprocess, 133.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "390\n",
      "\n",
      "0: 384x640 2 persons, 139.7ms\n",
      "Speed: 1.0ms preprocess, 139.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "391\n",
      "\n",
      "0: 384x640 2 persons, 153.9ms\n",
      "Speed: 2.1ms preprocess, 153.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "392\n",
      "\n",
      "0: 384x640 3 persons, 134.3ms\n",
      "Speed: 2.1ms preprocess, 134.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "393\n",
      "\n",
      "0: 384x640 3 persons, 143.3ms\n",
      "Speed: 2.0ms preprocess, 143.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "394\n",
      "\n",
      "0: 384x640 3 persons, 135.5ms\n",
      "Speed: 2.9ms preprocess, 135.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "395\n",
      "\n",
      "0: 384x640 4 persons, 162.1ms\n",
      "Speed: 2.0ms preprocess, 162.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "396\n",
      "\n",
      "0: 384x640 3 persons, 142.3ms\n",
      "Speed: 1.7ms preprocess, 142.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "397\n",
      "\n",
      "0: 384x640 3 persons, 137.2ms\n",
      "Speed: 2.1ms preprocess, 137.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "398\n",
      "\n",
      "0: 384x640 3 persons, 130.1ms\n",
      "Speed: 1.0ms preprocess, 130.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "399\n",
      "\n",
      "0: 384x640 2 persons, 154.7ms\n",
      "Speed: 2.0ms preprocess, 154.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "400\n",
      "\n",
      "0: 384x640 3 persons, 148.9ms\n",
      "Speed: 2.0ms preprocess, 148.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "401\n",
      "\n",
      "0: 384x640 3 persons, 135.3ms\n",
      "Speed: 3.0ms preprocess, 135.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "402\n",
      "\n",
      "0: 384x640 3 persons, 146.5ms\n",
      "Speed: 2.0ms preprocess, 146.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "403\n",
      "\n",
      "0: 384x640 3 persons, 140.7ms\n",
      "Speed: 1.7ms preprocess, 140.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "404\n",
      "\n",
      "0: 384x640 2 persons, 168.9ms\n",
      "Speed: 2.0ms preprocess, 168.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "405\n",
      "\n",
      "0: 384x640 2 persons, 142.3ms\n",
      "Speed: 2.0ms preprocess, 142.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "406\n",
      "\n",
      "0: 384x640 2 persons, 144.7ms\n",
      "Speed: 2.5ms preprocess, 144.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "407\n",
      "\n",
      "0: 384x640 2 persons, 131.3ms\n",
      "Speed: 2.0ms preprocess, 131.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "408\n",
      "\n",
      "0: 384x640 2 persons, 155.5ms\n",
      "Speed: 2.9ms preprocess, 155.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "409\n",
      "\n",
      "0: 384x640 2 persons, 145.0ms\n",
      "Speed: 2.1ms preprocess, 145.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "410\n",
      "\n",
      "0: 384x640 2 persons, 143.4ms\n",
      "Speed: 2.0ms preprocess, 143.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "411\n",
      "\n",
      "0: 384x640 2 persons, 141.1ms\n",
      "Speed: 3.0ms preprocess, 141.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "412\n",
      "\n",
      "0: 384x640 2 persons, 146.8ms\n",
      "Speed: 2.0ms preprocess, 146.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "413\n",
      "\n",
      "0: 384x640 2 persons, 147.0ms\n",
      "Speed: 2.0ms preprocess, 147.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "414\n",
      "\n",
      "0: 384x640 2 persons, 133.9ms\n",
      "Speed: 2.9ms preprocess, 133.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "415\n",
      "\n",
      "0: 384x640 2 persons, 172.0ms\n",
      "Speed: 2.0ms preprocess, 172.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "416\n",
      "\n",
      "0: 384x640 3 persons, 143.2ms\n",
      "Speed: 3.3ms preprocess, 143.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "417\n",
      "\n",
      "0: 384x640 3 persons, 134.5ms\n",
      "Speed: 2.0ms preprocess, 134.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "418\n",
      "\n",
      "0: 384x640 2 persons, 169.1ms\n",
      "Speed: 2.0ms preprocess, 169.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "419\n",
      "\n",
      "0: 384x640 2 persons, 148.0ms\n",
      "Speed: 1.0ms preprocess, 148.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "420\n",
      "\n",
      "0: 384x640 2 persons, 134.6ms\n",
      "Speed: 2.0ms preprocess, 134.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "421\n",
      "\n",
      "0: 384x640 2 persons, 156.8ms\n",
      "Speed: 3.0ms preprocess, 156.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "422\n",
      "\n",
      "0: 384x640 3 persons, 131.5ms\n",
      "Speed: 3.3ms preprocess, 131.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "423\n",
      "\n",
      "0: 384x640 2 persons, 148.0ms\n",
      "Speed: 2.2ms preprocess, 148.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "424\n",
      "\n",
      "0: 384x640 2 persons, 168.5ms\n",
      "Speed: 1.3ms preprocess, 168.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "425\n",
      "\n",
      "0: 384x640 2 persons, 132.6ms\n",
      "Speed: 3.0ms preprocess, 132.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "426\n",
      "\n",
      "0: 384x640 2 persons, 131.4ms\n",
      "Speed: 1.0ms preprocess, 131.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "427\n",
      "\n",
      "0: 384x640 2 persons, 155.9ms\n",
      "Speed: 2.0ms preprocess, 155.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "428\n",
      "\n",
      "0: 384x640 2 persons, 135.4ms\n",
      "Speed: 2.0ms preprocess, 135.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "429\n",
      "\n",
      "0: 384x640 2 persons, 133.5ms\n",
      "Speed: 2.0ms preprocess, 133.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "430\n",
      "\n",
      "0: 384x640 2 persons, 155.7ms\n",
      "Speed: 2.0ms preprocess, 155.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "431\n",
      "\n",
      "0: 384x640 3 persons, 130.1ms\n",
      "Speed: 2.0ms preprocess, 130.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "432\n",
      "\n",
      "0: 384x640 3 persons, 131.3ms\n",
      "Speed: 1.0ms preprocess, 131.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "433\n",
      "\n",
      "0: 384x640 3 persons, 1 sports ball, 129.1ms\n",
      "Speed: 3.0ms preprocess, 129.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "434\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 158.4ms\n",
      "Speed: 2.7ms preprocess, 158.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "435\n",
      "\n",
      "0: 384x640 2 persons, 132.4ms\n",
      "Speed: 3.0ms preprocess, 132.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "436\n",
      "\n",
      "0: 384x640 2 persons, 130.8ms\n",
      "Speed: 3.0ms preprocess, 130.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "437\n",
      "\n",
      "0: 384x640 2 persons, 174.6ms\n",
      "Speed: 2.7ms preprocess, 174.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "438\n",
      "\n",
      "0: 384x640 2 persons, 133.8ms\n",
      "Speed: 3.0ms preprocess, 133.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "439\n",
      "\n",
      "0: 384x640 3 persons, 133.6ms\n",
      "Speed: 2.9ms preprocess, 133.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "440\n",
      "\n",
      "0: 384x640 2 persons, 136.0ms\n",
      "Speed: 2.0ms preprocess, 136.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Hands UP\n",
      "441\n",
      "\n",
      "0: 384x640 2 persons, 152.5ms\n",
      "Speed: 2.0ms preprocess, 152.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "442\n",
      "\n",
      "0: 384x640 2 persons, 130.5ms\n",
      "Speed: 2.1ms preprocess, 130.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "443\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 136.4ms\n",
      "Speed: 2.0ms preprocess, 136.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "444\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 144.2ms\n",
      "Speed: 1.5ms preprocess, 144.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "445\n",
      "\n",
      "0: 384x640 2 persons, 147.6ms\n",
      "Speed: 1.0ms preprocess, 147.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "446\n",
      "\n",
      "0: 384x640 2 persons, 148.7ms\n",
      "Speed: 2.0ms preprocess, 148.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "447\n",
      "\n",
      "0: 384x640 2 persons, 138.5ms\n",
      "Speed: 1.0ms preprocess, 138.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "448\n",
      "\n",
      "0: 384x640 2 persons, 132.4ms\n",
      "Speed: 2.1ms preprocess, 132.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "449\n",
      "\n",
      "0: 384x640 2 persons, 148.2ms\n",
      "Speed: 2.6ms preprocess, 148.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "450\n",
      "\n",
      "0: 384x640 2 persons, 147.1ms\n",
      "Speed: 2.0ms preprocess, 147.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "451\n",
      "\n",
      "0: 384x640 2 persons, 134.5ms\n",
      "Speed: 1.0ms preprocess, 134.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "452\n",
      "\n",
      "0: 384x640 2 persons, 139.9ms\n",
      "Speed: 2.1ms preprocess, 139.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "453\n",
      "\n",
      "0: 384x640 2 persons, 141.5ms\n",
      "Speed: 1.6ms preprocess, 141.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "454\n",
      "\n",
      "0: 384x640 2 persons, 146.6ms\n",
      "Speed: 1.9ms preprocess, 146.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "455\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 157.3ms\n",
      "Speed: 1.9ms preprocess, 157.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "456\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 148.6ms\n",
      "Speed: 2.0ms preprocess, 148.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "457\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 157.7ms\n",
      "Speed: 1.0ms preprocess, 157.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "458\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 135.0ms\n",
      "Speed: 2.0ms preprocess, 135.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "459\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 143.8ms\n",
      "Speed: 2.2ms preprocess, 143.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "460\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 140.9ms\n",
      "Speed: 2.1ms preprocess, 140.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "461\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 141.6ms\n",
      "Speed: 3.0ms preprocess, 141.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "462\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 148.7ms\n",
      "Speed: 2.2ms preprocess, 148.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "463\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 145.2ms\n",
      "Speed: 2.1ms preprocess, 145.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "464\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 133.3ms\n",
      "Speed: 1.7ms preprocess, 133.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "465\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 134.3ms\n",
      "Speed: 2.0ms preprocess, 134.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "466\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 1 chair, 162.5ms\n",
      "Speed: 2.0ms preprocess, 162.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "467\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 156.6ms\n",
      "Speed: 2.0ms preprocess, 156.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "468\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 135.7ms\n",
      "Speed: 1.4ms preprocess, 135.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "469\n",
      "\n",
      "0: 384x640 2 persons, 154.8ms\n",
      "Speed: 2.0ms preprocess, 154.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "470\n",
      "\n",
      "0: 384x640 2 persons, 130.4ms\n",
      "Speed: 2.0ms preprocess, 130.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "471\n",
      "\n",
      "0: 384x640 2 persons, 1 airplane, 157.6ms\n",
      "Speed: 2.0ms preprocess, 157.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "472\n",
      "\n",
      "0: 384x640 2 persons, 147.3ms\n",
      "Speed: 1.0ms preprocess, 147.3ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "473\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 136.7ms\n",
      "Speed: 2.0ms preprocess, 136.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "474\n",
      "\n",
      "0: 384x640 2 persons, 1 sports ball, 1 chair, 154.9ms\n",
      "Speed: 2.0ms preprocess, 154.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "475\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 137.7ms\n",
      "Speed: 1.8ms preprocess, 137.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "476\n",
      "\n",
      "0: 384x640 2 persons, 136.5ms\n",
      "Speed: 2.3ms preprocess, 136.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "477\n",
      "\n",
      "0: 384x640 2 persons, 145.2ms\n",
      "Speed: 2.0ms preprocess, 145.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "478\n",
      "\n",
      "0: 384x640 2 persons, 146.1ms\n",
      "Speed: 3.0ms preprocess, 146.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "479\n",
      "\n",
      "0: 384x640 2 persons, 137.9ms\n",
      "Speed: 2.0ms preprocess, 137.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "480\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 151.9ms\n",
      "Speed: 2.0ms preprocess, 151.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "481\n",
      "\n",
      "0: 384x640 2 persons, 147.5ms\n",
      "Speed: 3.0ms preprocess, 147.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "482\n",
      "\n",
      "0: 384x640 3 persons, 145.0ms\n",
      "Speed: 3.0ms preprocess, 145.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "483\n",
      "\n",
      "0: 384x640 2 persons, 146.1ms\n",
      "Speed: 2.0ms preprocess, 146.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "484\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     14\u001b[0m count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 15\u001b[0m detected_persons \u001b[38;5;241m=\u001b[39m detect_person(model, frame)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box, score, class_id, pose_label \u001b[38;5;129;01min\u001b[39;00m detected_persons:\n\u001b[0;32m     19\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerate_random_name()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m, in \u001b[0;36mdetect_person\u001b[1;34m(model, frame)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_person\u001b[39m(model, frame):\n\u001b[1;32m----> 2\u001b[0m     results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(frame)\n\u001b[0;32m      3\u001b[0m     detected_persons \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:444\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream)\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:254\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 254\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:456\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 456\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39membed)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:102\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:120\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:141\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 141\u001b[0m x \u001b[38;5;241m=\u001b[39m m(x)  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    142\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    239\u001b[0m     y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x))\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mc:\\Users\\alimo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Process each video\n",
    "frame_counter = 0\n",
    "count=0\n",
    "\n",
    "for video_file in os.listdir(video_dir):\n",
    "    if video_file.endswith('.mp4'):\n",
    "        video_path = os.path.join(video_dir, video_file)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            count+=1\n",
    "            detected_persons = detect_person(model, frame)\n",
    "\n",
    "            for box, score, class_id, pose_label in detected_persons:\n",
    "                \n",
    "                file_name = f'{generate_random_name()}.jpg'\n",
    "                file_path = os.path.join(Handsup_output_dir,file_name)\n",
    "                cv2.imwrite(file_path, frame)\n",
    "                \n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                bbox_file_path = os.path.join(bbox_output_dir, file_name)\n",
    "                cv2.imwrite(bbox_file_path, image_rgb)\n",
    "\n",
    "                # create_pascal_voc_annotation(file_name, frame.shape, bounding_boxes, xml_dir)\n",
    "                create_xml_for_bounding_box(box, file_name.replace('.jpg', ''), xml_dir)\n",
    "                frame_counter += 1\n",
    "            print(count)\n",
    "        cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
